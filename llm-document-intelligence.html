<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Multi-Model LLM Document Intelligence Pipeline - Morteza Mogharrab</title>
    <meta name="description" content="Production-grade document AI system supporting OpenAI, Anthropic, and Ollama backends. Processes 450+ records/minute with 98%+ accuracy.">
    <link rel="stylesheet" href="styles.css">
    <link rel="stylesheet" href="project-page.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Space+Grotesk:wght@400;500;600;700&family=Inter:wght@400;500;600&display=swap" rel="stylesheet">
    <link rel="icon" href="assets/favicon.png" sizes="32x32">
</head>
<body>
    <!-- Theme Toggle -->
    <button class="theme-toggle" id="themeToggle" aria-label="Toggle theme">
        <svg class="moon-icon" viewBox="0 0 24 24">
            <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"/>
        </svg>
        <svg class="sun-icon" viewBox="0 0 24 24">
            <circle cx="12" cy="12" r="5"/>
            <line x1="12" y1="1" x2="12" y2="3"/>
            <line x1="12" y1="21" x2="12" y2="23"/>
            <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/>
            <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/>
            <line x1="1" y1="12" x2="3" y2="12"/>
            <line x1="21" y1="12" x2="23" y2="12"/>
            <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/>
            <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/>
        </svg>
    </button>

    <!-- Scroll Progress -->
    <div class="scroll-progress" id="scrollProgress"></div>

    <div class="project-container">
        <!-- Back Navigation -->
        <nav class="back-nav">
            <a href="index.html" class="back-link">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <path d="M19 12H5M12 19l-7-7 7-7"/>
                </svg>
                Back to Portfolio
            </a>
        </nav>

        <!-- Project Hero -->
        <header class="project-hero">
            <div class="project-badge-hero">Featured Project</div>
            <h1 class="project-hero-title">Multi-Model LLM Document Intelligence Pipeline</h1>
            <p class="project-hero-subtitle">Production-Grade Intelligent Document Processing System</p>
            
            <!-- Quick Stats Grid -->
            <div class="hero-stats-grid">
                <div class="stat-card">
                    <span class="stat-value">450+</span>
                    <span class="stat-label">records/min</span>
                </div>
                <div class="stat-card">
                    <span class="stat-value">98%</span>
                    <span class="stat-label">accuracy</span>
                </div>
                <div class="stat-card">
                    <span class="stat-value">3</span>
                    <span class="stat-label">backends</span>
                </div>
                <div class="stat-card">
                    <span class="stat-value">$0-0.50</span>
                    <span class="stat-label">per 1K records</span>
                </div>
            </div>

            <!-- Project Links -->
            <div class="project-links">
                <a href="https://github.com/morteza-mogharrab/llm-document-intelligence" target="_blank" class="btn-primary">
                    <svg viewBox="0 0 24 24" fill="currentColor">
                        <path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/>
                    </svg>
                    View on GitHub
                </a>
                <a href="https://github.com/morteza-mogharrab/llm-document-intelligence/blob/main/docs/ARCHITECTURE.md" target="_blank" class="btn-secondary">
                    View Documentation
                </a>
            </div>
        </header>

        <main class="project-content">
            <!-- Project Metadata -->
            <section class="project-meta-section">
                <div class="meta-grid">
                    <div class="meta-item">
                        <span class="meta-label">Project Type</span>
                        <span class="meta-value">Open-Source Production System</span>
                    </div>
                    <div class="meta-item">
                        <span class="meta-label">Role</span>
                        <span class="meta-value">Solo Developer & Architect</span>
                    </div>
                    <div class="meta-item">
                        <span class="meta-label">Timeline</span>
                        <span class="meta-value">December 2024 (Active)</span>
                    </div>
                    <div class="meta-item">
                        <span class="meta-label">Tech Stack</span>
                        <span class="meta-value">Python, OpenAI, Anthropic, Ollama</span>
                    </div>
                </div>
            </section>

            <!-- Overview Stats Table -->
            <section class="stats-table-section">
                <h2>Project Overview</h2>
                <div class="stats-table">
                    <div class="stats-row">
                        <span class="stats-metric">Throughput</span>
                        <span class="stats-achievement">450+ records/minute (cloud), 60/min (local)</span>
                    </div>
                    <div class="stats-row">
                        <span class="stats-metric">Accuracy</span>
                        <span class="stats-achievement">98%+ structured extraction reliability</span>
                    </div>
                    <div class="stats-row">
                        <span class="stats-metric">Backends Supported</span>
                        <span class="stats-achievement">3 (OpenAI, Anthropic, Ollama)</span>
                    </div>
                    <div class="stats-row">
                        <span class="stats-metric">Concurrent Processing</span>
                        <span class="stats-achievement">10x worker parallelization</span>
                    </div>
                    <div class="stats-row">
                        <span class="stats-metric">Lines of Code</span>
                        <span class="stats-achievement">1,000+ production-grade Python</span>
                    </div>
                    <div class="stats-row">
                        <span class="stats-metric">Documentation</span>
                        <span class="stats-achievement">Comprehensive (Architecture + Performance)</span>
                    </div>
                    <div class="stats-row">
                        <span class="stats-metric">Cost Optimization</span>
                        <span class="stats-achievement">$0/1K records (local) to $0.50/1K (cloud)</span>
                    </div>
                </div>
            </section>

            <!-- Strategic Context -->
            <section class="content-section">
                <h2>The Challenge</h2>
                <p class="lead-text">Modern enterprises process thousands of documents dailyâ€”from HR resume screening to contract analysis and financial document classification. Manual review is expensive, slow, and error-prone. While LLM APIs offer powerful natural language understanding, production deployment requires solving critical engineering challenges:</p>
                
                <div class="challenge-grid">
                    <div class="challenge-card">
                        <div class="challenge-icon">âš¡</div>
                        <h3>Rate Limiting</h3>
                        <p>Cloud APIs throttle requests (50-500/min)â€”naive implementations fail at scale</p>
                    </div>
                    <div class="challenge-card">
                        <div class="challenge-icon">ðŸ’°</div>
                        <h3>Cost Management</h3>
                        <p>Processing 10K documents can cost $5-50 depending on backend choice</p>
                    </div>
                    <div class="challenge-card">
                        <div class="challenge-icon">ðŸ”’</div>
                        <h3>Reliability</h3>
                        <p>Network failures, API timeouts, and parsing errors affect production systems</p>
                    </div>
                    <div class="challenge-card">
                        <div class="challenge-icon">ðŸ”„</div>
                        <h3>Vendor Lock-in</h3>
                        <p>Single API dependency creates risk and limits optimization opportunities</p>
                    </div>
                    <div class="challenge-card">
                        <div class="challenge-icon">ðŸ§µ</div>
                        <h3>Thread Safety</h3>
                        <p>Concurrent processing requires careful synchronization to avoid race conditions</p>
                    </div>
                </div>
            </section>

            <!-- Technical Requirements -->
            <section class="content-section">
                <h2>Technical Requirements</h2>
                
                <div class="requirements-grid">
                    <div class="req-column">
                        <h3>Functional</h3>
                        <ul class="requirement-list">
                            <li>Process structured datasets (CSV/Excel) with 1K-100K records</li>
                            <li>Extract 9+ fields per document with strict schema validation</li>
                            <li>Support multiple LLM backends for cost/performance optimization</li>
                            <li>Achieve >95% extraction accuracy with automatic retry logic</li>
                            <li>Handle 100+ concurrent requests without rate limit failures</li>
                        </ul>
                    </div>
                    <div class="req-column">
                        <h3>Non-Functional</h3>
                        <ul class="requirement-list">
                            <li><strong>Performance:</strong> Sub-second latency per document, 400+ records/minute throughput</li>
                            <li><strong>Scalability:</strong> Linear scaling from 100 to 100K records</li>
                            <li><strong>Security:</strong> Zero hardcoded credentials, environment-based config</li>
                            <li><strong>Maintainability:</strong> Modular architecture with <200 lines per module</li>
                            <li><strong>Observability:</strong> Comprehensive logging, error tracking, performance metrics</li>
                        </ul>
                    </div>
                </div>
            </section>

            <!-- Core Contributions -->
            <section class="content-section">
                <h2>Core Technical Contributions</h2>

                <!-- Contribution 1 -->
                <div class="contribution-block">
                    <div class="contribution-number">01</div>
                    <div class="contribution-content">
                        <h3>Multi-Backend LLM Integration Architecture</h3>
                        <p><strong>Challenge:</strong> Integrate three fundamentally different LLM providers with distinct APIs, response formats, and capabilities.</p>
                        
                        <p><strong>Solution:</strong> Implemented Strategy Pattern with backend adapters:</p>
                        
                        <div class="code-block">
<pre><code># Unified interface across backends
class DocumentAnalyzer:
    def analyze_document(self, row_data):
        # Backend-agnostic processing
        pass</code></pre>
                        </div>

                        <div class="backend-comparison">
                            <div class="backend-card">
                                <h4>OpenAI GPT-4o-mini</h4>
                                <ul>
                                    <li>450 requests/minute rate limit</li>
                                    <li>$0.50 per 1K records cost</li>
                                    <li>Best for: High-volume batch processing</li>
                                </ul>
                            </div>
                            <div class="backend-card">
                                <h4>Anthropic Claude Sonnet 4</h4>
                                <ul>
                                    <li>45 requests/minute (multi-turn + web search)</li>
                                    <li>$3.00 per 1K records cost</li>
                                    <li>Best for: Research-intensive analysis</li>
                                </ul>
                            </div>
                            <div class="backend-card">
                                <h4>Ollama (Local Qwen 2.5-32B)</h4>
                                <ul>
                                    <li>No API limits (hardware-bound)</li>
                                    <li>$0 cost (compute only)</li>
                                    <li>Best for: Privacy-sensitive data</li>
                                </ul>
                            </div>
                        </div>

                        <div class="impact-box">
                            <strong>Impact:</strong> Achieved 99% backend compatibilityâ€”switch providers with zero code changes.
                        </div>
                    </div>
                </div>

                <!-- Contribution 2 -->
                <div class="contribution-block">
                    <div class="contribution-number">02</div>
                    <div class="contribution-content">
                        <h3>High-Performance Concurrent Processing Engine</h3>
                        <p><strong>Challenge:</strong> Maximize throughput within strict API rate limits while ensuring thread safety.</p>
                        
                        <p><strong>Solution:</strong> Implemented ThreadPoolExecutor with intelligent worker management:</p>
                        
                        <div class="code-block">
<pre><code>with ThreadPoolExecutor(max_workers=10) as executor:
    futures = [executor.submit(analyzer.analyze_document, r) for r in rows]</code></pre>
                        </div>

                        <div class="performance-metrics">
                            <div class="perf-metric">
                                <span class="perf-number">7.6x</span>
                                <span class="perf-label">Throughput improvement</span>
                            </div>
                            <div class="perf-metric">
                                <span class="perf-number">84%</span>
                                <span class="perf-label">Efficiency (actual vs theoretical)</span>
                            </div>
                            <div class="perf-metric">
                                <span class="perf-number">99.2%</span>
                                <span class="perf-label">Reliability (5K job test)</span>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Contribution 3 -->
                <div class="contribution-block">
                    <div class="contribution-number">03</div>
                    <div class="contribution-content">
                        <h3>Thread-Safe Token Bucket Rate Limiter</h3>
                        <p><strong>Challenge:</strong> Prevent API throttling across concurrent threads while maximizing utilization.</p>
                        
                        <p><strong>Solution:</strong> Implemented token bucket algorithm with thread safety:</p>
                        
                        <div class="code-block">
<pre><code>class ThreadSafeRateLimiter:
    def __init__(self, max_per_minute, tokens_per_request, max_tokens_per_minute):
        self.lock = Lock()  # Thread-safe access
        self.timestamps = deque()  # Sliding window
        
        # Dual limits: requests AND tokens
        safe_rate = min(
            max_per_minute,
            (max_tokens_per_minute / tokens_per_request) * 0.85
        )</code></pre>
                        </div>

                        <div class="feature-list">
                            <div class="feature-item">
                                <svg viewBox="0 0 24 24" fill="currentColor"><path d="M9 16.2L4.8 12l-1.4 1.4L9 19 21 7l-1.4-1.4L9 16.2z"/></svg>
                                <span>Dual-limit enforcement (requests AND tokens)</span>
                            </div>
                            <div class="feature-item">
                                <svg viewBox="0 0 24 24" fill="currentColor"><path d="M9 16.2L4.8 12l-1.4 1.4L9 19 21 7l-1.4-1.4L9 16.2z"/></svg>
                                <span>Thread synchronization with Python Lock</span>
                            </div>
                            <div class="feature-item">
                                <svg viewBox="0 0 24 24" fill="currentColor"><path d="M9 16.2L4.8 12l-1.4 1.4L9 19 21 7l-1.4-1.4L9 16.2z"/></svg>
                                <span>85% safety margin prevents burst throttling</span>
                            </div>
                            <div class="feature-item">
                                <svg viewBox="0 0 24 24" fill="currentColor"><path d="M9 16.2L4.8 12l-1.4 1.4L9 19 21 7l-1.4-1.4L9 16.2z"/></svg>
                                <span>Sliding window for accurate rate calculation</span>
                            </div>
                        </div>

                        <div class="impact-box">
                            <strong>Impact:</strong> Zero rate limit errors in production (tested with 5K+ requests).
                        </div>
                    </div>
                </div>

                <!-- Contribution 4 -->
                <div class="contribution-block">
                    <div class="contribution-number">04</div>
                    <div class="contribution-content">
                        <h3>Robust Structured Output Parsing & Validation</h3>
                        <p><strong>Challenge:</strong> LLMs occasionally deviate from required output formatâ€”production systems need 100% parse success.</p>
                        
                        <p><strong>Solution:</strong> Multi-layer validation with fuzzy matching:</p>
                        
                        <div class="validation-layers">
                            <div class="layer">
                                <strong>1. Format validation:</strong> Check for 9 pipe-separated fields
                            </div>
                            <div class="layer">
                                <strong>2. Type validation:</strong> Ensure integers are integers, enums match expected values
                            </div>
                            <div class="layer">
                                <strong>3. Range validation:</strong> Clamp scores to 0-100, probabilities to 0-100
                            </div>
                            <div class="layer">
                                <strong>4. Fuzzy matching:</strong> "Ontario" matches even if model outputs "ontario" or "ON"
                            </div>
                        </div>

                        <div class="results-comparison">
                            <div class="result-item">
                                <span class="result-backend">Ollama (local)</span>
                                <span class="result-accuracy">98.1%</span>
                            </div>
                            <div class="result-item">
                                <span class="result-backend">OpenAI (cloud)</span>
                                <span class="result-accuracy">99.2%</span>
                            </div>
                            <div class="result-item">
                                <span class="result-backend">Anthropic Claude</span>
                                <span class="result-accuracy">99.5%</span>
                            </div>
                        </div>
                    </div>
                </div>
            </section>

            <!-- Results & Impact -->
            <section class="content-section">
                <h2>Results & Impact</h2>
                
                <div class="impact-table">
                    <div class="impact-row header">
                        <span>Metric</span>
                        <span>Baseline (Manual)</span>
                        <span>With System</span>
                        <span>Improvement</span>
                    </div>
                    <div class="impact-row">
                        <span>Processing Time (1K docs)</span>
                        <span>~100 hours</span>
                        <span>~3 minutes</span>
                        <span class="highlight">2,000x faster</span>
                    </div>
                    <div class="impact-row">
                        <span>Cost per 1K docs</span>
                        <span>$2,000 (labor)</span>
                        <span>$0.50 (OpenAI)</span>
                        <span class="highlight">99.98% reduction</span>
                    </div>
                    <div class="impact-row">
                        <span>Accuracy</span>
                        <span>95% (human error)</span>
                        <span>98%+ (validated)</span>
                        <span class="highlight">3% improvement</span>
                    </div>
                    <div class="impact-row">
                        <span>Throughput</span>
                        <span>10/hour</span>
                        <span>450/minute</span>
                        <span class="highlight">2,700x improvement</span>
                    </div>
                </div>

                <h3>Real-World Use Cases</h3>
                <div class="use-case-grid">
                    <div class="use-case-card">
                        <h4>HR Tech - Resume Screening</h4>
                        <ul>
                            <li>Process 5,000 job applications in 13 minutes</li>
                            <li>Extract 9 strategic fields per application</li>
                            <li>Cost: $2.17 (OpenAI) vs. $10,000 manual screening</li>
                        </ul>
                    </div>
                    <div class="use-case-card">
                        <h4>Legal Tech - Contract Analysis</h4>
                        <ul>
                            <li>Analyze 1,000 contracts in 3 minutes</li>
                            <li>Extract key clauses, identify risks</li>
                            <li>Cost: $0 (local Ollama) for privacy compliance</li>
                        </ul>
                    </div>
                    <div class="use-case-card">
                        <h4>Financial Services - Invoice Processing</h4>
                        <ul>
                            <li>Classify 10,000 invoices in 30 minutes</li>
                            <li>Extract vendor, amount, date, category</li>
                            <li>Cost: $5 (OpenAI) vs. $2,000 manual data entry</li>
                        </ul>
                    </div>
                </div>
            </section>

            <!-- Technology Stack -->
            <section class="content-section">
                <h2>Technology Stack</h2>
                
                <div class="tech-stack-grid">
                    <div class="tech-stack-category">
                        <h3>Core Technologies</h3>
                        <div class="tech-pills-grid">
                            <span class="tech-pill">Python 3.9+</span>
                            <span class="tech-pill">pandas</span>
                            <span class="tech-pill">python-dotenv</span>
                            <span class="tech-pill">tiktoken</span>
                        </div>
                    </div>

                    <div class="tech-stack-category">
                        <h3>LLM SDKs</h3>
                        <div class="tech-pills-grid">
                            <span class="tech-pill">OpenAI SDK</span>
                            <span class="tech-pill">Anthropic SDK</span>
                            <span class="tech-pill">Ollama</span>
                            <span class="tech-pill">GPT-4o-mini</span>
                            <span class="tech-pill">Claude Sonnet 4</span>
                            <span class="tech-pill">Qwen 2.5-32B</span>
                        </div>
                    </div>

                    <div class="tech-stack-category">
                        <h3>Concurrency & Data Structures</h3>
                        <div class="tech-pills-grid">
                            <span class="tech-pill">ThreadPoolExecutor</span>
                            <span class="tech-pill">threading.Lock</span>
                            <span class="tech-pill">collections.deque</span>
                            <span class="tech-pill">regex (re)</span>
                        </div>
                    </div>

                    <div class="tech-stack-category">
                        <h3>DevOps & Tools</h3>
                        <div class="tech-pills-grid">
                            <span class="tech-pill">Git/GitHub</span>
                            <span class="tech-pill">VS Code</span>
                            <span class="tech-pill">pip/venv</span>
                            <span class="tech-pill">Markdown</span>
                        </div>
                    </div>
                </div>
            </section>

            <!-- Key Learnings -->
            <section class="content-section">
                <h2>Key Engineering Learnings</h2>
                
                <div class="learning-grid">
                    <div class="learning-card">
                        <h3>Concurrency Isn't Free</h3>
                        <p>Learned that 20 workers performs worse than 10 due to overhead. Optimal worker count = 2x CPU cores for I/O-bound tasks. Always measure, don't assume more workers = better.</p>
                    </div>
                    <div class="learning-card">
                        <h3>Rate Limiting is Critical</h3>
                        <p>Naive implementations hit API limits within seconds. Token budget matters as much as request count. 85% safety margin prevents burst-induced failures.</p>
                    </div>
                    <div class="learning-card">
                        <h3>LLMs Need Constraints</h3>
                        <p>Without strict schema enforcement, models hallucinate formats. Examples in prompts improve compliance by 20%+. Parsing must be defensiveâ€”assume models will deviate.</p>
                    </div>
                    <div class="learning-card">
                        <h3>Multi-Backend Architecture Pays Off</h3>
                        <p>Switching from OpenAI to Ollama = $5,000/year savings at scale. Anthropic's web search enables use cases OpenAI can't handle. Abstraction cost < 50 lines, flexibility benefit = infinite.</p>
                    </div>
                    <div class="learning-card">
                        <h3>Documentation Drives Adoption</h3>
                        <p>Comprehensive README reduced setup questions to zero. Architecture docs enable contributors to understand design decisions. Performance benchmarks help users choose the right backend.</p>
                    </div>
                </div>
            </section>

            <!-- CTA Section -->
            <section class="cta-section">
                <h2>Explore the Project</h2>
                <p>Open-source and production-ready. Contributions welcome!</p>
                
                <div class="cta-buttons">
                    <a href="https://github.com/morteza-mogharrab/llm-document-intelligence" target="_blank" class="btn-cta-primary">
                        <svg viewBox="0 0 24 24" fill="currentColor">
                            <path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/>
                        </svg>
                        View on GitHub
                    </a>
                    <a href="https://github.com/morteza-mogharrab/llm-document-intelligence/blob/main/docs/ARCHITECTURE.md" target="_blank" class="btn-cta-secondary">
                        Read Documentation
                    </a>
                </div>

                <div class="installation-box">
                    <h3>Try It Yourself</h3>
                    <div class="code-block">
<pre><code>git clone https://github.com/morteza-mogharrab/llm-document-intelligence.git
cd llm-document-intelligence
pip install -r requirements.txt
cp env.example .env  # Add your API key
python src/document_analyzer_openai.py</code></pre>
                    </div>
                </div>
            </section>

            <!-- Footer -->
            <footer class="project-footer">
                <p>Built with Python 3.9+ | OpenAI GPT-4 | Anthropic Claude Sonnet 4 | Ollama</p>
                <p>Licensed under MIT | Open Source | Production-Ready</p>
            </footer>
        </main>
    </div>

    <script src="script.js"></script>
</body>
</html>